{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><b>Final Project Report Group 42- Heart Failure Fatality</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "    \n",
    "Cardiovascular diseases kill approximately 17 million people in the world, including heart attacks, strokes, and heart failure. In particular, heart failure is caused when the heart cannot successfully send the required amount of blood to the body (Chicco, 2020), and can occur for numerous reasons such as diabetes, high blood pressure, and other heart conditions or diseases. With the emergence and accessibility of electronic health records, it is now possible to use data from patients who have experienced heart failure and find trends and patterns amongst variables that could be possible predictors for people who are at risk of heart failure. Due to the vital nature of the heart finding trends among variables as predictors of heart failure has become a priority among doctors and researchers alike. Our project was to take a data set comprised of data taken from people who had suffered from heart failure and build a classifying model that could predict a person's chance of survival after heart failure. A data set collected at the Faisalabad Institute of Cardiology and at the Allied Hospital in Faisalabad contains the data of 299 patients which consisted of 105 women and 194 men who had all experienced heart failure. The dataset contained 13 features which ranged from physical, clinical, and lifestyle characteristics. This included categorical variables like sex, diabetes, and smoking; as well as numerical variables such as platelet count, serum creatine levels, and ejection fraction. This data set also contained the information on whether the patient had died in the 130 days follow-up after their heart failure referred to as a death event. Through the use of forward selection, we were able to identify two variables that were strong predictors of death events. These two variables, serum creatine and ejection fraction were used to build our classifying model that would take in the values of our predictors and classify whether this patient would experience a death event or not following 130 days after heart failure. This classifier would allow us to answer the question of if given a person's serum creatine levels and ejection fraction will that person survive within 130 days after their heart failure?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methods and Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘tidyr’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Warning message:\n",
      "“package ‘tidymodels’ was built under R version 4.0.2”\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 0.1.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom    \u001b[39m 0.7.0      \u001b[32m✔\u001b[39m \u001b[34mrecipes  \u001b[39m 0.1.13\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials    \u001b[39m 0.0.9      \u001b[32m✔\u001b[39m \u001b[34mrsample  \u001b[39m 0.0.7 \n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer    \u001b[39m 0.5.4      \u001b[32m✔\u001b[39m \u001b[34mtune     \u001b[39m 0.1.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata\u001b[39m 0.0.2      \u001b[32m✔\u001b[39m \u001b[34mworkflows\u001b[39m 0.2.0 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip  \u001b[39m 0.1.3      \u001b[32m✔\u001b[39m \u001b[34myardstick\u001b[39m 0.0.7 \n",
      "\n",
      "Warning message:\n",
      "“package ‘broom’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dials’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘infer’ was built under R version 4.0.3”\n",
      "Warning message:\n",
      "“package ‘modeldata’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘parsnip’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘recipes’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tune’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘workflows’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘yardstick’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading necessary packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "\n",
    "# Setting the seed to ensure reproducability \n",
    "set.seed(42)\n",
    "\n",
    "# Setting the number of maximum rows which will be displayed whenever a data tibble needs to be outputed \n",
    "options(repr.matrix.max.rows = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, appropriate packages were added to the file to use their inbuilt functions. A seed was set to ensure reproducibility so that the random values are always the same. And the maximum rows to be displayed when a tibble needs to be outputted was set to 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  age = \u001b[32mcol_double()\u001b[39m,\n",
      "  anaemia = \u001b[32mcol_double()\u001b[39m,\n",
      "  creatinine_phosphokinase = \u001b[32mcol_double()\u001b[39m,\n",
      "  diabetes = \u001b[32mcol_double()\u001b[39m,\n",
      "  ejection_fraction = \u001b[32mcol_double()\u001b[39m,\n",
      "  high_blood_pressure = \u001b[32mcol_double()\u001b[39m,\n",
      "  platelets = \u001b[32mcol_double()\u001b[39m,\n",
      "  serum_creatinine = \u001b[32mcol_double()\u001b[39m,\n",
      "  serum_sodium = \u001b[32mcol_double()\u001b[39m,\n",
      "  sex = \u001b[32mcol_double()\u001b[39m,\n",
      "  smoking = \u001b[32mcol_double()\u001b[39m,\n",
      "  time = \u001b[32mcol_double()\u001b[39m,\n",
      "  DEATH_EVENT = \u001b[32mcol_double()\u001b[39m\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reads in data as well as turns relevant double columns into factors \n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv\"\n",
    "\n",
    "# tranforms the data variables which need to factors into the factor datatype \n",
    "heart_data <- read_csv(url)%>%\n",
    "    mutate(sex = as_factor(sex))%>%\n",
    "    mutate(smoking = as_factor(smoking))%>%\n",
    "    mutate(DEATH_EVENT = as_factor(DEATH_EVENT))%>%\n",
    "    mutate(high_blood_pressure = as_factor(high_blood_pressure))%>%\n",
    "    mutate(diabetes = as_factor(diabetes))%>%\n",
    "    mutate(anaemia= as_factor(anaemia)) \n",
    "\n",
    "\n",
    "#creates factor levels for columns that make sense with column name, not just 0 and 1 \n",
    "levels(heart_data$sex) <- c(\"female\",\"male\")\n",
    "levels(heart_data$smoking) <- c(\"no\",\"yes\")\n",
    "levels(heart_data$DEATH_EVENT) <- c(\"died\",\"survived\")\n",
    "levels(heart_data$high_blood_pressure) <- c(\"no\",\"yes\")\n",
    "levels(heart_data$diabetes) <- c(\"no\",\"yes\")\n",
    "levels(heart_data$anaemia) <- c(\"no\",\"yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the dataset was read in as csv file. All the catagoriacal variables were transformed into factors datatype by using mutate function and as_factor function. As some columns include factors labeled \"0\" and \"1\", new factor levels were created with c function. These were as follows: \n",
    "- \"female\"/\"male\" in \"sex\"\n",
    "- \"no\"/\"yes\" in \"smoking\" \n",
    "- \"died\"/\"survived\" in \"DEATH_EVENT\"\n",
    "- \"no\"/\"yes\" in \"high_blood_pressure\"\n",
    "- \"no\"/\"yes\" in \"diabetes\"\n",
    "- \"no\"/\"yes\" in \"aneamia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 225 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>age</th><th scope=col>anaemia</th><th scope=col>creatinine_phosphokinase</th><th scope=col>diabetes</th><th scope=col>ejection_fraction</th><th scope=col>high_blood_pressure</th><th scope=col>platelets</th><th scope=col>serum_creatinine</th><th scope=col>serum_sodium</th><th scope=col>sex</th><th scope=col>smoking</th><th scope=col>time</th><th scope=col>DEATH_EVENT</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>75</td><td>no </td><td>582</td><td>no</td><td>20</td><td>yes</td><td>265000</td><td>1.9</td><td>130</td><td>male</td><td>no </td><td>4</td><td>survived</td></tr>\n",
       "\t<tr><td>50</td><td>yes</td><td>111</td><td>no</td><td>20</td><td>no </td><td>210000</td><td>1.9</td><td>137</td><td>male</td><td>no </td><td>7</td><td>survived</td></tr>\n",
       "\t<tr><td>90</td><td>yes</td><td> 47</td><td>no</td><td>40</td><td>yes</td><td>204000</td><td>2.1</td><td>132</td><td>male</td><td>yes</td><td>8</td><td>survived</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>55</td><td>no</td><td>1820</td><td>no </td><td>38</td><td>no</td><td>270000</td><td>1.2</td><td>139</td><td>female</td><td>no </td><td>271</td><td>died</td></tr>\n",
       "\t<tr><td>45</td><td>no</td><td>2060</td><td>yes</td><td>60</td><td>no</td><td>742000</td><td>0.8</td><td>138</td><td>female</td><td>no </td><td>278</td><td>died</td></tr>\n",
       "\t<tr><td>45</td><td>no</td><td>2413</td><td>no </td><td>38</td><td>no</td><td>140000</td><td>1.4</td><td>140</td><td>male  </td><td>yes</td><td>280</td><td>died</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 225 × 13\n",
       "\\begin{tabular}{lllllllllllll}\n",
       " age & anaemia & creatinine\\_phosphokinase & diabetes & ejection\\_fraction & high\\_blood\\_pressure & platelets & serum\\_creatinine & serum\\_sodium & sex & smoking & time & DEATH\\_EVENT\\\\\n",
       " <dbl> & <fct> & <dbl> & <fct> & <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <fct> & <fct> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 75 & no  & 582 & no & 20 & yes & 265000 & 1.9 & 130 & male & no  & 4 & survived\\\\\n",
       "\t 50 & yes & 111 & no & 20 & no  & 210000 & 1.9 & 137 & male & no  & 7 & survived\\\\\n",
       "\t 90 & yes &  47 & no & 40 & yes & 204000 & 2.1 & 132 & male & yes & 8 & survived\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 55 & no & 1820 & no  & 38 & no & 270000 & 1.2 & 139 & female & no  & 271 & died\\\\\n",
       "\t 45 & no & 2060 & yes & 60 & no & 742000 & 0.8 & 138 & female & no  & 278 & died\\\\\n",
       "\t 45 & no & 2413 & no  & 38 & no & 140000 & 1.4 & 140 & male   & yes & 280 & died\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 225 × 13\n",
       "\n",
       "| age &lt;dbl&gt; | anaemia &lt;fct&gt; | creatinine_phosphokinase &lt;dbl&gt; | diabetes &lt;fct&gt; | ejection_fraction &lt;dbl&gt; | high_blood_pressure &lt;fct&gt; | platelets &lt;dbl&gt; | serum_creatinine &lt;dbl&gt; | serum_sodium &lt;dbl&gt; | sex &lt;fct&gt; | smoking &lt;fct&gt; | time &lt;dbl&gt; | DEATH_EVENT &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 75 | no  | 582 | no | 20 | yes | 265000 | 1.9 | 130 | male | no  | 4 | survived |\n",
       "| 50 | yes | 111 | no | 20 | no  | 210000 | 1.9 | 137 | male | no  | 7 | survived |\n",
       "| 90 | yes |  47 | no | 40 | yes | 204000 | 2.1 | 132 | male | yes | 8 | survived |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 55 | no | 1820 | no  | 38 | no | 270000 | 1.2 | 139 | female | no  | 271 | died |\n",
       "| 45 | no | 2060 | yes | 60 | no | 742000 | 0.8 | 138 | female | no  | 278 | died |\n",
       "| 45 | no | 2413 | no  | 38 | no | 140000 | 1.4 | 140 | male   | yes | 280 | died |\n",
       "\n"
      ],
      "text/plain": [
       "    age anaemia creatinine_phosphokinase diabetes ejection_fraction\n",
       "1   75  no      582                      no       20               \n",
       "2   50  yes     111                      no       20               \n",
       "3   90  yes      47                      no       40               \n",
       "⋮   ⋮   ⋮       ⋮                        ⋮        ⋮                \n",
       "223 55  no      1820                     no       38               \n",
       "224 45  no      2060                     yes      60               \n",
       "225 45  no      2413                     no       38               \n",
       "    high_blood_pressure platelets serum_creatinine serum_sodium sex    smoking\n",
       "1   yes                 265000    1.9              130          male   no     \n",
       "2   no                  210000    1.9              137          male   no     \n",
       "3   yes                 204000    2.1              132          male   yes    \n",
       "⋮   ⋮                   ⋮         ⋮                ⋮            ⋮      ⋮      \n",
       "223 no                  270000    1.2              139          female no     \n",
       "224 no                  742000    0.8              138          female no     \n",
       "225 no                  140000    1.4              140          male   yes    \n",
       "    time DEATH_EVENT\n",
       "1   4    survived   \n",
       "2   7    survived   \n",
       "3   8    survived   \n",
       "⋮   ⋮    ⋮          \n",
       "223 271  died       \n",
       "224 278  died       \n",
       "225 280  died       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#splits the data into training and testing data \n",
    "heart_data_split <- initial_split(heart_data, prop = .75, strata = DEATH_EVENT)\n",
    "heart_train <- training(heart_data_split)\n",
    "heart_test <- testing(heart_data_split)\n",
    " \n",
    "heart_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the dataset was split into training data and testing data for classification. The training data consist of 75% of all rows randomly chosen from the dataset with initial_split function. This function siffles the data so no particular order/pattern is present in the 2 sets, and also stratifies the data so both sets have the same proportion of positive and negative classes. This makes the 2 sets comparable. The proportion 75% was chosen to use the vast majority of data for training while keeping sufficient number of observations for testing, regarding that our dataset only has 299 observations. This helps our model to be trained on the majority of the data hence being more accurate, while giving us sufficient data to evaluate its accuracy as well. This is one of the splits suggested in the course book as well (refer to the end of the notebook for reference). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non essential columns from the dataset and only keep numerical to run forward propagation\n",
    "heart_train <- heart_train %>% \n",
    "    select(-anaemia, -diabetes, -high_blood_pressure, -sex, -smoking, -time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, due to medical significance (Chicco, 2020), we decided that we will use \"DEATH_EVENT\" as our output variable which we will try to classify, hence we removed all the other categorical datatypes from the heart_test dataset using the select function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>size</th><th scope=col>model_string</th><th scope=col>accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>DEATH_EVENT ~ ejection_fraction                                                                     </td><td>0.6568423</td></tr>\n",
       "\t<tr><td>2</td><td>DEATH_EVENT ~ ejection_fraction+serum_creatinine                                                    </td><td>0.7822354</td></tr>\n",
       "\t<tr><td>3</td><td>DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium                                       </td><td>0.7994247</td></tr>\n",
       "\t<tr><td>4</td><td>DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase              </td><td>0.7774879</td></tr>\n",
       "\t<tr><td>5</td><td>DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase+age          </td><td>0.7686957</td></tr>\n",
       "\t<tr><td>6</td><td>DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase+age+platelets</td><td>0.7511111</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 3\n",
       "\\begin{tabular}{lll}\n",
       " size & model\\_string & accuracy\\\\\n",
       " <int> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & DEATH\\_EVENT \\textasciitilde{} ejection\\_fraction                                                                      & 0.6568423\\\\\n",
       "\t 2 & DEATH\\_EVENT \\textasciitilde{} ejection\\_fraction+serum\\_creatinine                                                     & 0.7822354\\\\\n",
       "\t 3 & DEATH\\_EVENT \\textasciitilde{} ejection\\_fraction+serum\\_creatinine+serum\\_sodium                                        & 0.7994247\\\\\n",
       "\t 4 & DEATH\\_EVENT \\textasciitilde{} ejection\\_fraction+serum\\_creatinine+serum\\_sodium+creatinine\\_phosphokinase               & 0.7774879\\\\\n",
       "\t 5 & DEATH\\_EVENT \\textasciitilde{} ejection\\_fraction+serum\\_creatinine+serum\\_sodium+creatinine\\_phosphokinase+age           & 0.7686957\\\\\n",
       "\t 6 & DEATH\\_EVENT \\textasciitilde{} ejection\\_fraction+serum\\_creatinine+serum\\_sodium+creatinine\\_phosphokinase+age+platelets & 0.7511111\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 3\n",
       "\n",
       "| size &lt;int&gt; | model_string &lt;chr&gt; | accuracy &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 | DEATH_EVENT ~ ejection_fraction                                                                      | 0.6568423 |\n",
       "| 2 | DEATH_EVENT ~ ejection_fraction+serum_creatinine                                                     | 0.7822354 |\n",
       "| 3 | DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium                                        | 0.7994247 |\n",
       "| 4 | DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase               | 0.7774879 |\n",
       "| 5 | DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase+age           | 0.7686957 |\n",
       "| 6 | DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase+age+platelets | 0.7511111 |\n",
       "\n"
      ],
      "text/plain": [
       "  size\n",
       "1 1   \n",
       "2 2   \n",
       "3 3   \n",
       "4 4   \n",
       "5 5   \n",
       "6 6   \n",
       "  model_string                                                                                        \n",
       "1 DEATH_EVENT ~ ejection_fraction                                                                     \n",
       "2 DEATH_EVENT ~ ejection_fraction+serum_creatinine                                                    \n",
       "3 DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium                                       \n",
       "4 DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase              \n",
       "5 DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase+age          \n",
       "6 DEATH_EVENT ~ ejection_fraction+serum_creatinine+serum_sodium+creatinine_phosphokinase+age+platelets\n",
       "  accuracy \n",
       "1 0.6568423\n",
       "2 0.7822354\n",
       "3 0.7994247\n",
       "4 0.7774879\n",
       "5 0.7686957\n",
       "6 0.7511111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CODE TO SELECT THE BEST PREDICTOR VARIABLES (code has been adapted from the DSCI 100 course book.) \n",
    "# (Citation is in references section)\n",
    "\n",
    "# Evaluating which predictive variables to choose\n",
    "\n",
    "# creating an object of names of all predictive variables called \"names\"\n",
    "names <- colnames(heart_train %>% select(-DEATH_EVENT))\n",
    "\n",
    "# creating an empty tibble to store the final results\n",
    "accuracies <- tibble(size = integer(), \n",
    "                     model_string = character(), # this is the first argument to the \"recipe\" function\n",
    "                     accuracy = numeric())\n",
    "\n",
    "# creating a model specification for the classifier\n",
    "heart_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>% \n",
    "     set_engine(\"kknn\") %>% \n",
    "     set_mode(\"classification\")\n",
    "\n",
    "# creating a dataframe of all candidate k values \n",
    "k_vals <- tibble(neighbors = seq(1:10))\n",
    "\n",
    "# creating a 5-fold cross-validation object\n",
    "heart_vfold <- vfold_cv(heart_train, v = 5, strata = DEATH_EVENT)\n",
    "\n",
    "# storing the total number of predictors in object \"n_total\"\n",
    "n_total <- length(names)\n",
    "\n",
    "# stores the selected predictors\n",
    "selected <- c()\n",
    "\n",
    "# for every size from 1 to the total number of predictors\n",
    "for (i in 1:n_total) {\n",
    "    # for every predictor still not added yet\n",
    "    accs <- list()\n",
    "    models <- list()\n",
    "    for (j in 1:length(names)) {\n",
    "        # create a model string for this combination of predictors\n",
    "        preds_new <- c(selected, names[[j]])\n",
    "        model_string <- paste(\"DEATH_EVENT\", \"~\", paste(preds_new, collapse=\"+\"))\n",
    "\n",
    "        # create a recipe from the model string\n",
    "        heart_recipe <- recipe(as.formula(model_string), \n",
    "                                data = heart_train) %>% \n",
    "                          step_scale(all_predictors()) %>% \n",
    "                          step_center(all_predictors())\n",
    "\n",
    "        # tune the KNN classifier with these predictors, \n",
    "        # and collect the accuracy for the best K\n",
    "        acc <- workflow() %>% \n",
    "              add_recipe(heart_recipe) %>% \n",
    "              add_model(heart_spec) %>% \n",
    "              tune_grid(resamples = heart_vfold, grid = k_vals) %>% \n",
    "              collect_metrics() %>% \n",
    "              filter(.metric == \"accuracy\") %>% \n",
    "              summarize(mx = max(mean))\n",
    "        acc <- acc$mx %>% unlist()\n",
    "\n",
    "        # add this result to the dataframe\n",
    "        accs[[j]] <- acc\n",
    "        models[[j]] <- model_string\n",
    "    }\n",
    "    jstar <- which.max(unlist(accs))\n",
    "    accuracies <- accuracies %>% \n",
    "      add_row(size = i, \n",
    "              model_string = models[[jstar]], \n",
    "              accuracy = accs[[jstar]])\n",
    "    selected <- c(selected, names[[jstar]])\n",
    "    names <- names[-jstar]\n",
    "}\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method (forward propagation): This code block ran an predictor variable selection algorithm called \"forward propagation\". This algorithm essentially “propagates” through all the variables, concatinating singular predictor variables after each other for every iteration of the loop. So, a k-nn classifier is built for each set of predictors, its best k value (from k = 1 to 15) and its appropriate accuracy is calculated. The subset of variables which return the higher values of accuracies are the ones which are appropriate for the classification. Ofcourse this is done with cross validation (5 v fold) to make sure our results are reliable. (Reasons for the attributes chosen for the k values and number of folds in cross validation are explained later. So is the detailed working of the k-nn classifier). This was achievable primarily due to the “paste” function which helped form a model specification for each set of predictor by concatinating them seperated with the “+” signs. as.formula function inside recipe function was used to add the model string. Moreover, two for loops were used to achieve this: the first one to account for the increasing predictor set sizes, and the second one to analyse which predictor to add to each cycle/iteration. An important factor which made us select this algorithm for our predictor variable selection was computational cost. There are many other (more productive) algorithms present for this task such as best subset selection, however most of them take a long time to run while not giving any significant difference in the overall accuracy of the classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result (forward propagation): The result of this evaluation showed that the top 2 accuracies are the second and the third rows. The accuracy predicted with ejection_fraction and serum_creatinine was 78.22% and that predicted with ejection_fraction, serum_creatinine, and serum_sodium was 79.94%. However, biologically, ejection fraction and serum creatinine alone are the best predictors of death event due to medical significance (Chicco, 2020). This does not differ from our evaluation as the accuracy of prediction with ejection_fraction and serum_creatinine is the second-highest. Therefore, these two numerical variables were chosen as predictive variables for our classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only appropriate columns from training set and testing set (ejection_fraction, serum_creatinine, DEATH_EVENT)\n",
    "heart_train <- heart_train %>% \n",
    "    select(ejection_fraction, serum_creatinine, DEATH_EVENT)\n",
    "\n",
    "heart_test<- heart_test%>%\n",
    "    select(ejection_fraction, serum_creatinine, DEATH_EVENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected our predictor variables, we plot the initial graph to look at their effect on death event and how they relate to the final output class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height = 10, repr.plot.width = 12)\n",
    "\n",
    "# Plotting the initial graph for our variables for exploratory data analysis\n",
    "heart_plot<- heart_train%>%\n",
    "    ggplot(aes(x= serum_creatinine, y = ejection_fraction))+\n",
    "    geom_point(aes(color = DEATH_EVENT), size = 3)+\n",
    "    labs(x = \"Serum Creatinine Levels (mg/dL)\", y = \"Ejection Fraction (%)\", \n",
    "         title = \"Serum Creatinine and Ejection Fraction\\n as Predictors for a Death Event\",\n",
    "         color = \"Patient Outcome\")+\n",
    "    theme(text = element_text(size = 20), plot.title = element_text(hjust = .5)) + \n",
    "    scale_color_manual(labels = c(\"Died\", \"Survived\"), \n",
    "                     values = c(\"orange2\", \"steelblue2\"))\n",
    "heart_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted this for our initial exploration. We set the size of the plot and text to be easily readible while we also used color blind friendly colors for our classification shading. The plot above shows the distribution of our two predictors in relation to our variable that we are trying to predict, death event (in this graph it is labeled as patient outcome, but that is the same as death event). We can easily notice that the major cluster of death outcomes are in the region where ejection fractions are between 25% - 60% and when logarithmic serum creatinine is between 0.3 - 2. Hence a clear decision boundary can be formulated which will be done in further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Making our classifier and using the variables found from forward propagation to find the best k value\n",
    "\n",
    "# Creating variable k_vals which stores the candidate k values in form of a tibble\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 15, by = 1))\n",
    "\n",
    "# Creating a recipe with recipe function, class = DEATH_EVENT and predictive variables are ejection_fraction\n",
    "# and serum_creatinine. Only heart_train data is used with both the predictive variables scaled. \n",
    "final_recipe <- recipe(DEATH_EVENT ~ ejection_fraction+serum_creatinine, data = heart_train) %>% \n",
    "    step_scale(all_predictors()) %>% \n",
    "    step_center(all_predictors())\n",
    "\n",
    "# Creating a model specification for k-nn classification: argument for \"neighbors\" is set to tune() to \n",
    "# get best k value for the classification\n",
    "kmin_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>% \n",
    "    set_engine(\"kknn\") %>% \n",
    "    set_mode(\"classification\")\n",
    "\n",
    "# Creating a 5 v fold cross validation argument with strata = DEATH_EVENT as that is the variable we want to predict\n",
    "final_vfold <- vfold_cv(heart_train, v = 5, strata = DEATH_EVENT)\n",
    "\n",
    "# Putting everything in a workflow, using tune_grid to repeat on all candidate k value with cross validation \n",
    "# and collect_metrics to calculate the accuracy for each run\n",
    "kmin_results <- workflow() %>%\n",
    "    add_recipe(final_recipe) %>% \n",
    "    add_model(kmin_spec) %>% \n",
    "    tune_grid(resamples = final_vfold, grid = k_vals) %>% \n",
    "    collect_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After predictive variables were chosen, the KNN classifier was created with those variables in order to choose the best k value. The \"rectangular\" input into the weight_func argument was to give each neighbour only 1 voting power. As 5-fold cross-validation would be performed here as well, the neighbors argument was \"tune()\". We used 5-fold cross validation as with our data size, its is sufficient to help us avoid any \"lucky\" subsets which might influence the accuracy while being computationally efficient. Similarly the k values were chosen from 1 to 15 to make our code computationally light while giving us a broad enough range for our data set size of 299 data points. The results for calculating accuracy for each run were then calculated as follows to get the best k value which returns the highest approximate accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in kmin_results %>% filter(.metric == \"accuracy\"): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in kmin_results %>% filter(.metric == \"accuracy\"): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Extracting only accuracy values from kminresults using filter function\n",
    "final_accuracies <- kmin_results %>% \n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "# Plotting a neighbors vs accuracy mean graph to see which k is the best\n",
    "accuracy_versus_k <- ggplot(final_accuracies, aes(x = neighbors, y = mean))+\n",
    "      geom_point() +\n",
    "      geom_line() +\n",
    "      labs(x = \"Neighbors\", y = \"Accuracy Estimate\", title = \"K value vs Accuracy Estimate\") +\n",
    "      scale_x_continuous(breaks = seq(0, 14, by = 1)) +  # adjusting the x-axis\n",
    "      scale_y_continuous(limits = c(0.4, 1.0)) + # adjusting the y-axis  \n",
    "      theme(text = element_text(size = 20), plot.title = element_text(hjust = .5))\n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plotted a graph for the mean accuracy which was recieved after collecting the metrics for every k value. As we can notice from the graph, any k value ranging from 7 to 15 gives around the same accuracy level, so ant of them can be used, however, since the actual peaks are k = 11, 12 and 14, these are now the candidates for our final k value. We now find the best k value using the arrange and slice functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the k value which offers the maximum accuracy from kmin_results\n",
    "k_min <- kmin_results %>% \n",
    "    filter(.metric == \"accuracy\") %>% \n",
    "    arrange(-mean) %>% \n",
    "    slice(1) %>% \n",
    "    select(neighbors, mean) %>% \n",
    "    rename(accuracy = mean)\n",
    "k_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly shows that the best K = 11 and testing accuracy is 78.7%. Now we try to evaluate this classifiers accuracy on the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining with the chosen K value of 11\n",
    "\n",
    "# Creating the final model specification with the best k value set as the argument for neighbors (11)\n",
    "final_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 11) %>% \n",
    "    set_engine(\"kknn\") %>% \n",
    "    set_mode(\"classification\")\n",
    "\n",
    "# Putting the final model specification and recipe into a wokflow and fitting it to heart_train \n",
    "final_fit  <- workflow() %>%\n",
    "    add_recipe(final_recipe) %>% \n",
    "    add_model(final_spec) %>% \n",
    "    fit(data = heart_train)\n",
    "\n",
    "# predicting the classes of heart test \n",
    "heart_prediction <- predict(final_fit, heart_test) %>% \n",
    "    bind_cols(heart_test)\n",
    "\n",
    "# Evaluating the accuracy of prediction made on heart test\n",
    "heart_prediction_accuracy <- heart_prediction %>% \n",
    "    metrics(truth = DEATH_EVENT, estimate = .pred_class) %>% \n",
    "    filter(.metric == \"accuracy\")\n",
    "heart_prediction_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the test accuracy by retraining a new classifier on heart_train with the best k value, that is k = 11. The specification was fitted onto the training data and then the predict function was used to predict the classes for the testing data. These predicted classes were then compared to the actual classes to calculate the test accuracy using the metrics function. This final testing accuracy hence came out to be 71.6% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_prediction_confusion <- heart_prediction %>% \n",
    "    conf_mat(truth = DEATH_EVENT, estimate = .pred_class)\n",
    "heart_prediction_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the only wrong classifications which we care about are the 10 when the truth = died and prediction = survived as those are the people who will not get approporiate healthcare to avoid death. The people who got a prediction of died but actually survived will not be affected that much since there are not major implications/costs for that predictin, Hence overall critical accuracy can be said to be around (40+13+11)/(40+10+11+13) ≈ 86.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a majority classifier (one which predicts died always) to see how well our classifier works against the majority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added a reference point using a majority classifier if it predicted died everytime it would have 68% accuracy.\n",
    "heart_data_proportions <- heart_train %>%\n",
    "                      group_by(DEATH_EVENT) %>%\n",
    "                      summarize(n = n()) %>%\n",
    "                      mutate(percent = 100*n/nrow(heart_train))\n",
    "\n",
    "heart_data_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority classifier seems to be outputing an accuracy of 68%, which is quite close to our actual testing accuracy. This suggests that the classification classifier which we created is not that strong. This will further be discussed in the discussion section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a prediction boundry plot for the classifier \n",
    "options(repr.plot.height = 10, repr.plot.width = 12)\n",
    "\n",
    "#scaling all the data before plotting it\n",
    "graph_data <- heart_data\n",
    "\n",
    "# recipe(DEATH_EVENT ~ ejection_fraction + serum_creatinine, data = heart_data)%>%\n",
    "#     step_scale(all_predictors())%>%\n",
    "#     step_center(all_predictors())%>%\n",
    "#     prep()%>%\n",
    "#     bake(heart_data)\n",
    "\n",
    "\n",
    "# create the grid of area/smoothness vals, and arrange in a data frame\n",
    "ef_grid <- seq(min(graph_data$ejection_fraction), \n",
    "                max(graph_data$ejection_fraction), \n",
    "                length.out = 100)\n",
    "sc_grid <- seq(min(graph_data$serum_creatinine), \n",
    "                max(graph_data$serum_creatinine), \n",
    "                length.out = 100)\n",
    "asgrid <- as_tibble(expand.grid(ejection_fraction = ef_grid, \n",
    "                                serum_creatinine = sc_grid))\n",
    "\n",
    "# use the fit workflow to make predictions at the grid points\n",
    "knnPredGrid <- predict(final_fit, asgrid)\n",
    "\n",
    "# bind the predictions as a new column with the grid points\n",
    "prediction_table <- bind_cols(knnPredGrid, asgrid) %>% \n",
    "  rename(DEATH_EVENT = .pred_class)\n",
    "\n",
    "# plot:\n",
    "# 1. the colored scatter of the original data\n",
    "# 2. the faded colored scatter for the grid points\n",
    "heart_prediction_plot <- ggplot() +\n",
    "  geom_point(data = graph_data, \n",
    "             mapping = aes(x = serum_creatinine, \n",
    "                           y = ejection_fraction, \n",
    "                           color = DEATH_EVENT), \n",
    "             alpha = 0.75, \n",
    "             size = 3) +\n",
    "  geom_point(data = prediction_table, \n",
    "             mapping = aes(x = serum_creatinine, \n",
    "                           y = ejection_fraction, \n",
    "                           color = DEATH_EVENT), \n",
    "             alpha = 0.09, \n",
    "             size = 7) +\n",
    "  labs(color = \"Diagnosis\", x = \"Serum Creatinine Levels (mg/dL)\", y = \"Ejection Fraction (%)\", \n",
    "         title = \"Serum Creatinine and Ejection Fraction\\n as Predictors for a Death Event\") +\n",
    "  scale_color_manual(labels = c(\"Died\", \"Survived\"), \n",
    "                     values = c(\"orange2\", \"steelblue2\")) +\n",
    "  theme(text = element_text(size = 20), plot.title = element_text(hjust = .5))\n",
    "\n",
    "heart_prediction_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot essentially summarizes the results of our classifier. We have created a decision boundary plot to see which patients die and which survive depending our either serum creatinine levels and ejection fraction. The actual points are the points from a scatter plot of Ejection fraction (%) versus Serum Creatinine levels (mg/dL) as predictors for a death event. Orange colour indicates people died and blue colour indicates survived. We had to follow a complicated method to achieve this (which was inspired from the DSCI 100 book). First, we created the grid of random creatinine/ejection values, and arrange it in a data frame using the as.grid function. Then we used the predict function to make predictions at the grid points. We used expand.grid function to predict the label of each, and visualize the predictions with a coloured scatter. Each point for this \"fake\" grid was given a high radius value and a low transparency so it looks like the graph is actually shaded. Finally, we overlay this plot with a plot of the actual data points from our heart_data dataset to see if the decision boundary aligns with the actual data. Hence our final results is a plot containing (1) the coloured scatter of the original data and (2) the faded coloured scatter for the grid points.\n",
    "\n",
    "As we can clearly see, the decision boundary aligns with the decision boundary which one would have intuitively created and is covering most of the data points correctly, hence the classifier seems to be working properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Discussion**\n",
    "\n",
    "\n",
    "The initial running of our forward selection model found that our best predictors of Death Events were serum creatine levels and ejection fraction.  Serum creatine is a waste product generated by creatine when muscle breakdowns(Chicco, 2020). Serum creatine is normally removed from the bloodstream via the kidneys but high levels of serum creatine may be an indication of renal dysfunction (Cole et al., 2012).  Renal dysfunction is a common comorbidity with acute and chronic heart failure however the complex interactions between the two are still poorly understood in the scientific community (Cole et al., 2012).  The Ejection Fraction is the proportion of blood pumped out through one contraction of the heart and in this data set is given as a percentage (Chicco, 2020).  While these predictors by themselves each have their own impact and connection to heart failure it was unclear what patterns and trends they would have when used together to predict a Death Event. We began by assembling a model using these two variables as predictors. Through the use of cross-validation and tune_grid() functions we ran our model on a range of k values from 1 to 15. We chose these values to give us the widest range of possible k values to build our model without getting too computationally costly. For our cross-validation model, we chose to do 5 folds in order to attain good accuracy without increasing the computation time of our model. From this we found k = 11 to have the highest accuracy across all k values. From our graph we can see that smaller K values could have been chosen with relatively similar accuracies, however due to the purpose of our model being responsible for human lives we decided to choose the k value with the highest accuracy possible for our classifier. After running our model with k = 11 we found that our model had an accuracy of 71.6%. When creating a confusion matrix it showed that our model had predicted 11 deaths as a classification for patients that had actually survived. Even though our model had incorrectly classified these observations we decided to include them as an accurate prediction since in a hospital setting this patient would still have survived. The more “critical” misclassifications, where our model predicted someone's survival when they died, added up to 11 as well. If we counted only does classifications as misclassifications it brought our total accuracy up to 84%. Our majority classifier which predicted the death of the patient every time had an accuracy of 68%. When we compare our model on a purely classification accuracy base it did not perform well. 71% is not acceptable when that means that potentially 30% of the cases will be misclassified which could result in numerous patients deaths. This also only slightly higher than our majority classification of 68% meaning that our model is barely outperforming a model that takes in zero input data. Even only focusing on the “critical” misclassifications which brought our model accuracy up to 84% is not acceptable for being responsible to predict who may be at risk of death. This data is perhaps not surprising given the vastly different biological roles our two predictors are involved with. Serum creatinine being related to renal dysfunction and ejection fraction being the heart's ability to pump blood do not appear to be related at all on the surface. While there are possible connections between renal dysfunction and heart failure it seemed unlikely that those two as predictors would be able to accurately predict a patient's chance of survival post heart failure. This findings further complicate the potential connections that can be drawn between kidney failure and heart failure. In order to better understand these connections, future studies may want to investigate other common indicators of kidney failure and heart failure and discover if any patterns or trends lie between them as predictors of survival.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "\n",
    "Cole, R. T.; Masoumi, A.; Triposkiadis, F.; Giamouzis, G.; Georgiopoulou, V.; Kalogeropoulos, A.; \n",
    "Butler, J. Renal Dysfunction in Heart Failure. Medical Clinics of North America 2012, 96 (5), 955–974.\n",
    "UCI Machine Learning Repository: Heart Failure Clinical Records Data Set. (n.d.). Retrieved \n",
    "March 5, 2022, from https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records \n",
    "\n",
    "Tiffany Timbers, T. C. (2022, March 2). Data science. Chapter 6 Classification II: evaluation and \n",
    "tuning. Retrieved March 5, 2022, from https://datasciencebook.ca/classification2.html\n",
    "\n",
    "Chicco, D., &amp; Jurman, G. (2020, February 3). Machine learning can predict survival of \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
